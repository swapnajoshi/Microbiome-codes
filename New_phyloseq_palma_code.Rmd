---
title: "New_phyloseq_palma_code"
author: "Swapna Mahurkar-Joshi"
date: "May 1, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


---
## Load Required Packages

Clear workspace prior to run.

```{r clear-workspace}
rm(list=ls())
```

```{r check-install-load-packages, warning=FALSE, message=FALSE}
# The required package list:
reqpkg = c("edgeR", "PoiClaClu", "phyloseq", "DESeq", 
           "foreach", "doParallel",
           "plyr", "reshape2", "ggplot2", "grid", "scales", "cluster")
# Check against installed packages:
inpkg = installed.packages()[, "Package"]
neededpkg = reqpkg[!reqpkg %in% inpkg]
if(length(neededpkg) > 0){
	stop(paste("Need to install the following package:", neededpkg))
}
# Load all required packages and show version
for(i in reqpkg){
	print(i)
	library(i, quietly=TRUE, verbose=FALSE, warn.conflicts=FALSE, character.only=TRUE)
	packageVersion(i)
}
# Show session info
sessionInfo()
```

Load some theme parameters for ggplot2.

```{r ggplot2-params}
theme_set(theme_bw())
pal = "Set1"
scale_colour_discrete <-  function(palname=pal, ...){
  scale_colour_brewer(palette=palname, ...)
}
scale_fill_discrete <-  function(palname=pal, ...){
	scale_fill_brewer(palette=palname, ...)
}
```
Sample parameters

```{r}
minobs <- 1L
```


```{r}
load("C:/Users/swapnajoshi-admin/Documents/GIT_workspace/IBSmicrobiomeProject/IBSmicrobiomeAnalysisR/data/consistantData/biopsyMicrobiome/ibsMicroLevel3Data.Rda")
```

```{r}
# Minimum number of reads to consider an OTU "observed" in a sample
minobs= 1L
```
# Define template

## Parameter definitions

The major factors contributing to the computation cost in this simulation example are the number of OTUs retained from the template `GlobalPatterns` dataset, which ultimately is used to dictate the length of the multinomials and their corresponding proportion vectors specified by $\pi$ (R variable `pi` or `pis`); and the number of samples being simulated. 

- `nOTUs` -- the number of most-prevalent OTUs to keep in simulation template, `r nOTUs`.
- `minobs` -- The minimum abundance value, `r minobs`, for which an OTU is "counted" as having been observed in a given sample. This is used for ranking OTUs according to the number of samples in which they appeared.
- `J` -- The number of samples per simulated table. For multitable analysis this needs to be consistent across tables, so included here in the beginning as a global parameter. Value for this simulation is `r J`.
- `mixfacs` -- The fold-weighting of the template multinomial compared with its mixed-in counterpart. Same in both directions (symetric mixing). 
- `ns` -- A vector of the expected values for the sampling depth that are nevertheless subject to the random sampling from the original template totals. The read numbers should not exceed the total number of reads in the template, so this is checked in the "simulation" (subsampling) module, and a ceiling used. The values for this vector of sampling depth means in this particular simulation is: `r ns`.


Trim OTUs that do not appear in very many samples in the template. Sort by prevalance (number of samples appeared) and then by abundance value. Trimmed to prev = 1

```{r trim-by-prevalence}
samobs = apply(otu_table(physeq), 1, function(x, m) sum(x > m), m=minobs)
otudf = data.frame(prev=samobs, sums=taxa_sums(physeq))
otudf = otudf[order(-otudf$prev, -otudf$sums), ]
nOTUs = 5552

```

Trim all but the first nOTUs
```{r trim-template-nOTUs}
physeq1 = prune_taxa(rownames(otudf)[1:nOTUs], physeq)
physeq1 
```
### DESeq normalization

From DESeq:
"The inference in DESeq relies on an estimation of the typical relationship between the data’s variance and their mean, or, equivalently, between the data’s dispersion and their mean. The dispersion can be understood as the square of the coefficient of biological variation. So, if a gene’s expression typically differs from replicate to replicate sample by 20%, this gene’s dispersion is 0.22 = .04. Note that the variance seen between counts is the sum of two components: the sample-to-sample variation just mentioned, and the uncertainty in measuring a concentration by counting reads. The latter, known as shot noise or Poisson noise, is the dominating noise source for lowly expressed genes. The former dominates for highly expressed genes. The sum of both, shot noise and dispersion, is considered in the differential expression inference. Hence, the variance v of count values is modelled as:

v = sμ + αs2μ2

$$
\upsilon = s\mu + \alpha{s}^2{\mu}^2
$$

where $\mu is the expected normalized count value (estimated by the average normalized count value), $s$ is the size factor for the sample under consideration, and $\alpha$ is the dispersion value for the gene under consideration. 
"

To estimate the dispersions, use the `estimateDispersions` function. Note that there are `method`, `sharingMode`, and `fitType` arguments to `estimateDispersions`, the choice of which are presumed to affect power. For the sample clustering simulation here, we have no "replicate" samples from a particular treatment or technical step. 

```{r deseq-variance-stabilization-transform}
deseq_varstab = function(physeq, sampleConditions=rep("A", nsamples(physeq)), ...){
	require("DESeq")
	# Enforce orientation.
	if( !taxa_are_rows(physeq) ){
		physeq <- t(physeq)
	}
	x = as(otu_table(physeq), "matrix")
	# The same tweak as for edgeR to avoid NaN problems
	# that cause the workflow to stall/crash.
	x = x + 1
	# Create annotated data.frame with the taxonomy table, in case it is useful later
	taxADF = as(data.frame(as(tax_table(physeq), "matrix"), stringsAsFactors=FALSE), "AnnotatedDataFrame")
	cds = newCountDataSet(x, sampleConditions, featureData=taxADF)
	# First estimate library size factors
	cds = estimateSizeFactors(cds)
	# Variance estimation, passing along additional options
	cds = estimateDispersions(cds, ...)
	# Determine which column(s) have the dispersion estimates
	dispcol = grep("disp\\_", colnames(fData(cds)))
	# Enforce that there are no infinite values in the dispersion estimates
	if( any(!is.finite(fData(cds)[, dispcol])) ){
		fData(cds)[which(!is.finite(fData(cds)[, dispcol])), dispcol] <- 0.0
	}
  vsmat = exprs(varianceStabilizingTransformation(cds))
  otu_table(physeq) <- otu_table(vsmat, taxa_are_rows=TRUE)
  return(physeq)
}
```

From DESeq vignette:

"As we estimated the dispersions from a small number of replicates, the estimates scatter with quite some sampling variance around their true values. An initial assumption that one could make is that the regression line shown in Figure 1 models the true underlying dispersions, and that the variation of the point estimates around simply reflects sampling variance. This is the assumption that we put forward in the first paper on DESeq. However, subsequent experience with larger data sets indicates that not all of the variability of the points around the regression line seen in Figure 1 is sampling variance: some of it reflects differences of the true, underlying variance between different genes. Hence, the default behaviour of DESeq now uses a more prudent or conservative approach: if a per-gene estimates lies below the regression line, we assume that this might indeed be sampling variance, and shift the estimate upwards to the value predicted by the regression line. If, however, the per-gene estimate lies above the line, we do not shift it downwards to the line, but rather keep it as is.

The option `sharingMode` of the function estimateDispersions can be used to control this behaviour. The value `sharingMode="maximum"` corresponds to the default. If you have many replicates (where many starts at around 7), the choice `sharingMode="gene-est-only"` will typically be more adequate. If you would like to use the behaviour described in [the original DESeq article], this is achieved by specifying `sharingMode="fit-only"`.

Another difference of the current DESeq version to the original method described in the paper is the way how the mean-dispersion relation is fitted. By default, estimateDispersions now performs a parametric fit: Using a gamma-family GLM, two coefficients $\alpha_{0}$, $\alpha_{1}$ are found to parametrize the fit as $\alpha = \alpha_{0} + \alpha_{1}/\mu$. (The values of the two coefficients can be found in the `fitInfo` object, as attribute coefficients to `dispFunc`.) For some data sets, the parametric fit may give bad results [or just fail], in which case one should try a local fit (the method described in the paper), which is available via the option `fitType="local"` to `estimateDispersions`.

In any case, the dispersion values which will be used by the subsequent testing are stored in the feature data slot of cds [use `fData`]."

To adjust the dispersion estimates, fix infinite values, use the `fData` accessor prior to calling the testing function.

### Perform normalizations 

```{r simpletrim}
simpletrim = function(physeq, J){
  if( taxa_are_rows(physeq) ){
    physeq = t(physeq)
  }
  # `prevalence` is the fraction of total samples in which
  # an OTU is observed at least `minobs` times.
  prevalence = apply(as(otu_table(physeq), "matrix"), 2, 
        function(x, minobs){sum(x > minobs)},
                     minobs)/(2*J)
  # Will only keep OTUs that appear in more than X% of samples
  keepOTUs = prevalence > 0.05
  # Keep only those OTUs with total reads greater
  # than 0.5x the number of samples. 
  keepOTUs = keepOTUs & taxa_sums(physeq) > (0.5*J)
  return(prune_taxa(keepOTUs, physeq))
}
```

Perform initializations, and trimming

```{r perform-initializations-trim}
# Initialize the simulation lists simlist0 and simlist
simlist0 = simlistuntrim =  simlist
# checks
#apply(as(otu_table(simlistuntrim[[1]]), "matrix"), 2, 
#      function(x, tot){sum(x>tot)}, minobs)/(2*J)
#sapply(lapply(simlistuntrim, taxa_sums), function(x, J){sum(x < (0.5*J))}, J)/nOTUs
# Trim simlist0
simlist0 = lapply(simlistuntrim, simpletrim, J)
```

### DESeq variance stabilization and distance calculation

```{r deseqdistwrap}
deseqdistwrap = function(physeq, ...){
  require("phylosq"); require("DESeq")
  physeqVS = deseq_varstab(physeq, method="blind", sharingMode="maximum", fitType="local")
  return(distance(physeqVS, ...))
}
```




































